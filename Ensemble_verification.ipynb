{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "# roc curve and auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# precision-recall curve and f1\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# Matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Voice\n",
    "import librosa\n",
    "import librosa.display\n",
    "from dtw import dtw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Data (.wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ['./voice_test_data/']  # Path where the voice/video are located\n",
    "data_path_save = ['./voice_test_data_wav/']\n",
    "extension_list = ('*.mpeg', '*.mp4','*.ogg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data from '.mpeg', '.mp4','.ogg' to '.wav'\n",
    "voice_dir = []\n",
    "for path in data_path:\n",
    "    for extension in extension_list:\n",
    "        _list = sorted(glob.glob(path + extension))\n",
    "        voice_dir += _list\n",
    "\n",
    "for i in range(len(voice_dir)):\n",
    "    wav_filename = data_path_save[0] + os.path.basename(voice_dir[i]).split('.')[0] + '.wav'\n",
    "    AudioSegment.from_file(voice_dir[i]).export(wav_filename, format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound = AudioSegment.from_file(wav_filename, format=\"wav\")\n",
    "play(sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_list =sorted(glob.glob(data_path_save[0] + '*.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(predictions, labels):\n",
    "    \n",
    "    treshold_max = np.max(predictions)\n",
    "    treshold_min = np.min(predictions)\n",
    "    P = np.sum(labels == 1)\n",
    "    N = np.sum(labels == 0)\n",
    "    step = (treshold_max - treshold_min)/3000\n",
    "    TPR_full = []\n",
    "    FPR_full = []\n",
    "    ROC_ACC_full = []\n",
    "    #print('*****************************************************************************')\n",
    "    for treshold in np.arange(treshold_min, treshold_max + step, step):\n",
    "        \n",
    "        #print(f'Treshold = {treshold:.4f}')\n",
    "        idx1 = predictions <= treshold\n",
    "        idx2 = predictions > treshold\n",
    "\n",
    "        TP = np.sum(labels[idx1] == 1)\n",
    "        FN = P - TP             \n",
    "        TN = np.sum(labels[idx2] == 0)\n",
    "        FP = N - TN\n",
    "        #print(f'TP = {TP:.0f}, FN = {FN:.0f}, TN = {TN:.0f}, FP = {FP:.0f}')\n",
    "        \n",
    "        # roc curve\n",
    "        TPR = float(TP/P)\n",
    "        TPR_full.append(TPR)\n",
    "        TNR = float(TN/N)\n",
    "        FPR = 1-TNR\n",
    "        FPR_full.append(FPR)\n",
    "        ROC_ACC = (TP + TN)/(P + N)\n",
    "        ROC_ACC_full.append(ROC_ACC)\n",
    "        #print(f'TPR = {TPR:.4f}, FPR = {FPR:.4f}, ROC_ACC = {ROC_ACC:.4f}')\n",
    "        \n",
    "    return TPR_full, FPR_full, ROC_ACC_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Model (MFCC + DTW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "mfcc_total = []\n",
    "for i in tqdm(range(len(wave_list))):\n",
    "    y, sr = librosa.load(wave_list[i])\n",
    "    mfcc = librosa.feature.mfcc(y,sr)   #Computing MFCC values\n",
    "    mfcc_total.append(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_total_labels = []\n",
    "mfcc_total_dist =  []\n",
    "for i in tqdm(range(len(wave_list)-1)):\n",
    "    \n",
    "    x = mfcc_total[i]\n",
    "    lx = int(os.path.basename(wave_list[i]).split('_')[1])\n",
    "    \n",
    "    for j in range(i+1,len(wave_list)):\n",
    "        \n",
    "        y = mfcc_total[j]\n",
    "        ly = int(os.path.basename(wave_list[j]).split('_')[1])\n",
    "        \n",
    "        dist, cost, acc_cost, path = dtw(x.T, y.T, dist=lambda x, y: norm(x - y, ord=2))\n",
    "        mfcc_total_dist.append(dist)\n",
    "        \n",
    "        if lx == ly:\n",
    "            label = int(1)\n",
    "            mfcc_total_labels.append(label)\n",
    "        else:\n",
    "            label = int(0)\n",
    "            mfcc_total_labels.append(label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mfcc total dist = \" + str(len(mfcc_total_dist)))\n",
    "print(\"mfcc total labels = \" + str(len(mfcc_total_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_predictions = np.array([mfcc_total_dist])\n",
    "mfcc_labels = np.array([mfcc_total_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_TPR, mfcc_FPR, mfcc_accuracy = calculate_results(mfcc_predictions, mfcc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy = \" + str(np.max(mfcc_accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplot(1, 2, 1)\n",
    "# plot the roc curve for the model\n",
    "plt.plot(mfcc_FPR, mfcc_TPR, marker='.', label='MFCC - ROC (TPR-FPR)')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# save and show plot\n",
    "plt.savefig('MFCC Test Results.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Showing multiple plots using subplot\n",
    "# plt.subplot(2, 2, 1) \n",
    "# mfcc1 = librosa.feature.mfcc(y1,sr1)   #Computing MFCC values\n",
    "# librosa.display.specshow(mfcc1)\n",
    "# plt.subplot(2, 2, 2)\n",
    "# mfcc2 = librosa.feature.mfcc(y2, sr2)\n",
    "# librosa.display.specshow(mfcc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(cost.T, origin='lower', cmap=plt.get_cmap('gray'), interpolation='nearest')\n",
    "# plt.plot(path[0], path[1], 'w')   #creating plot for DTW\n",
    "# plt.xlim((-0.5, cost.shape[0]-0.5))\n",
    "# plt.ylim((-0.5, cost.shape[1]-0.5))\n",
    "# plt.show()  #To display the plots graphically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model (Resemblyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resemblyzer import VoiceEncoder, preprocess_wav\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=3, suppress=True)\n",
    "encoder = VoiceEncoder()\n",
    "embed_total = []\n",
    "for i in tqdm(range(len(wave_list))):\n",
    "    fpath = Path(wave_list[i])\n",
    "    wav = preprocess_wav(fpath)\n",
    "    embed = encoder.embed_utterance(wav)\n",
    "    embed_total.append(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_total_labels = []\n",
    "embed_total_dist =  []\n",
    "f_dist = lambda x, y: norm(x - y, ord=2)\n",
    "for i in tqdm(range(len(wave_list)-1)):\n",
    "    \n",
    "    x = embed_total[i]\n",
    "    lx = int(os.path.basename(wave_list[i]).split('_')[1])\n",
    "    \n",
    "    for j in range(i+1,len(wave_list)):\n",
    "        \n",
    "        y = embed_total[j]\n",
    "        ly = int(os.path.basename(wave_list[j]).split('_')[1])\n",
    "        \n",
    "        dist = f_dist(x,y)\n",
    "        embed_total_dist.append(dist)\n",
    "        \n",
    "        if lx == ly:\n",
    "            label = int(1)\n",
    "            embed_total_labels.append(label)\n",
    "        else:\n",
    "            label = int(0)\n",
    "            embed_total_labels.append(label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"embed total dist = \" + str(len(embed_total_dist)))\n",
    "print(\"embed total labels = \" + str(len(embed_total_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_predictions = np.array([embed_total_dist])\n",
    "embed_labels = np.array([embed_total_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_TPR, embed_FPR, embed_accuracy = calculate_results(embed_predictions, embed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resemblyzer accuracy = \" + str(np.max(embed_accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplot(1, 2, 1)\n",
    "# plot the roc curve for the model\n",
    "plt.plot(embed_FPR, embed_TPR, marker='.', label='Resemblyzer ROC (TPR-FPR)')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# save and show plot\n",
    "plt.savefig('Resemblyzer Test Results.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Modal Voice Verification\n",
    "(Computer Vision + Deep Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_normalize(x):\n",
    "    \n",
    "    m = np.mean(x, axis=0)\n",
    "    std = np.std(x, axis=0)\n",
    "    normalized_x = 0.5 * (np.tanh(0.01 * ((x - m) / std)) + 1)\n",
    "    \n",
    "    return normalized_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_normalized = tanh_normalize(embed_predictions[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_normalized = tanh_normalize(mfcc_predictions[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exahustive Search\n",
    "for i in np.arange(0, 1, 0.1):\n",
    "    fusion_predictions = i*embed_normalized + (1-i)*mfcc_normalized\n",
    "    fusion_predictions = np.array([fusion_predictions])\n",
    "    fusion_labels = embed_labels\n",
    "    fusion_TPR, fusion_FPR, fusion_accuracy = calculate_results(fusion_predictions, fusion_labels)\n",
    "    print(f'weight = {i:0.1f} fusion accuracy = {np.max(fusion_accuracy):0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_predictions = 0.7*embed_normalized + 0.3*mfcc_normalized\n",
    "fusion_predictions = np.array([fusion_predictions])\n",
    "fusion_labels = embed_labels\n",
    "fusion_TPR, fusion_FPR, fusion_accuracy = calculate_results(fusion_predictions, fusion_labels)\n",
    "print(f'fusion accuracy = {np.max(fusion_accuracy):0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x = embed_FPR, \n",
    "    y = embed_TPR,\n",
    "    name=\"Resemblyzer\"       # this sets its legend entry\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x = mfcc_FPR, \n",
    "    y = mfcc_TPR,\n",
    "    name=\"MFCC\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x = fusion_FPR, \n",
    "    y = fusion_TPR,\n",
    "    name=\"Fusion\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    \n",
    "    title={\n",
    "        'text': \"Multi-Modal Voice Verification\",\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "\n",
    "    xaxis_title=\"False Positive Rate\",\n",
    "    yaxis_title=\"True Positive Rate\",\n",
    "    \n",
    "    font=dict(\n",
    "        family=\"Arial, monospace\",\n",
    "        size=20,\n",
    "        color=\"#000000\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MFCC accuracy = {np.max(mfcc_accuracy):0.4f}')\n",
    "print(f'Resemblyzer accuracy = {np.max(embed_accuracy):0.4f}')\n",
    "print(f'Fusion accuracy = {np.max(fusion_accuracy):0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "y1, sr1 = librosa.load(wave_list[1])\n",
    "x = librosa.feature.mfcc(y1,sr1)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "y2, sr2 = librosa.load(wave_list[2])\n",
    "y = librosa.feature.mfcc(y2,sr2) \n",
    "dist, cost, acc_cost, path = dtw(x.T, y.T, dist=lambda x, y: norm(x - y, ord=2))\n",
    "\n",
    "print(\"MFCC Process Time= \" + str(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = VoiceEncoder()\n",
    "import torch\n",
    "# # device config\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "fpath1 = Path(wave_list[1])\n",
    "wav1 = preprocess_wav(fpath1)\n",
    "embed1 = encoder.embed_utterance(wav1)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "fpath2 = Path(wave_list[2])\n",
    "wav2 = preprocess_wav(fpath2)\n",
    "embed2 = encoder.embed_utterance(wav2)\n",
    "\n",
    "dist = f_dist(embed1,embed2)\n",
    "print(\"Resemblyzer Process Time= \" + str(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
